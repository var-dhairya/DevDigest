import dotenv from 'dotenv'
import { fileURLToPath } from 'url'
import { dirname, join } from 'path'

// Load environment variables
const __filename = fileURLToPath(import.meta.url)
const __dirname = dirname(__filename)
dotenv.config({ path: join(__dirname, '..', '.env.local') })

import { connectDB } from '../lib/database.js'
import Source from '../models/Source.js'
import Content from '../models/Content.js'

async function testEnhancedFetching() {
  try {
    console.log('ğŸ§ª Testing Enhanced Fetching Algorithm...')
    console.log('=' .repeat(50))
    
    await connectDB()
    
    // Get a sample Reddit source for testing
    const redditSource = await Source.findOne({ 
      type: 'reddit', 
      isActive: true,
      'config.subreddit': { $exists: true }
    })
    
    if (!redditSource) {
      console.log('âŒ No Reddit sources found for testing')
      return
    }
    
    console.log(`ğŸ“‹ Testing with source: ${redditSource.name}`)
    console.log(`ğŸ¯ Subreddit: r/${redditSource.config.subreddit}`)
    console.log(`âš™ï¸ Config: ${redditSource.config.sortBy}/${redditSource.config.timeFilter}`)
    
    // Get current content count
    const contentBefore = await Content.countDocuments({ source: redditSource.name })
    console.log(`ğŸ“Š Current content count: ${contentBefore}`)
    
    // Test the enhanced refresh endpoint
    console.log('\nğŸš€ Triggering enhanced refresh...')
    
    const startTime = Date.now()
    const response = await fetch('http://localhost:3000/api/refresh', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      }
    })
    
    const endTime = Date.now()
    const duration = (endTime - startTime) / 1000
    
    if (!response.ok) {
      console.log(`âŒ Refresh API failed: ${response.status} ${response.statusText}`)
      const errorText = await response.text()
      console.log('Error details:', errorText)
      return
    }
    
    const result = await response.json()
    console.log(`â±ï¸ Refresh completed in ${duration.toFixed(2)} seconds`)
    
    // Get updated content count
    const contentAfter = await Content.countDocuments({ source: redditSource.name })
    const newContent = contentAfter - contentBefore
    
    console.log('\nğŸ“Š RESULTS:')
    console.log('=' .repeat(30))
    console.log(`âœ… API Success: ${result.success}`)
    console.log(`ğŸ“ˆ Total new posts: ${result.data?.totalFetched || 0}`)
    console.log(`ğŸ“‹ Sources processed: ${result.data?.sourcesProcessed || 0}`)
    console.log(`ğŸ¯ Max posts limit: ${result.data?.maxPostsLimit || 'N/A'}`)
    console.log(`â±ï¸ Duration: ${duration.toFixed(2)}s`)
    console.log(`ğŸ“Š ${redditSource.name} new content: ${newContent}`)
    
    if (result.data?.sourceStats) {
      console.log('\nğŸ“ˆ Source Type Breakdown:')
      const stats = result.data.sourceStats
      console.log(`ğŸ”´ Reddit: ${stats.reddit?.success || 0} success, ${stats.reddit?.failed || 0} failed, ${stats.reddit?.totalFetched || 0} posts`)
      console.log(`ğŸ“¡ RSS: ${stats.rss?.success || 0} success, ${stats.rss?.failed || 0} failed, ${stats.rss?.totalFetched || 0} posts`)
      console.log(`ğŸ”Œ API: ${stats.api?.success || 0} success, ${stats.api?.failed || 0} failed, ${stats.api?.totalFetched || 0} posts`)
    }
    
    // Test multiple refresh calls to ensure consistency
    console.log('\nğŸ”„ Testing consistency with multiple calls...')
    const consistencyResults = []
    
    for (let i = 1; i <= 3; i++) {
      console.log(`\nğŸ“ Call ${i}:`)
      const callStart = Date.now()
      
      const callResponse = await fetch('http://localhost:3000/api/refresh', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        }
      })
      
      const callEnd = Date.now()
      const callDuration = (callEnd - callStart) / 1000
      
      if (callResponse.ok) {
        const callResult = await callResponse.json()
        const callNewPosts = callResult.data?.totalFetched || 0
        consistencyResults.push({
          call: i,
          success: true,
          posts: callNewPosts,
          duration: callDuration
        })
        console.log(`âœ… Call ${i}: ${callNewPosts} posts in ${callDuration.toFixed(2)}s`)
      } else {
        consistencyResults.push({
          call: i,
          success: false,
          posts: 0,
          duration: callDuration
        })
        console.log(`âŒ Call ${i}: Failed in ${callDuration.toFixed(2)}s`)
      }
      
      // Small delay between calls
      await new Promise(resolve => setTimeout(resolve, 2000))
    }
    
    // Analyze consistency
    console.log('\nğŸ“Š CONSISTENCY ANALYSIS:')
    console.log('=' .repeat(30))
    const successfulCalls = consistencyResults.filter(r => r.success)
    const totalPosts = successfulCalls.reduce((sum, r) => sum + r.posts, 0)
    const avgPosts = successfulCalls.length > 0 ? totalPosts / successfulCalls.length : 0
    const avgDuration = successfulCalls.length > 0 ? 
      successfulCalls.reduce((sum, r) => sum + r.duration, 0) / successfulCalls.length : 0
    
    console.log(`âœ… Successful calls: ${successfulCalls.length}/3`)
    console.log(`ğŸ“ˆ Total posts across calls: ${totalPosts}`)
    console.log(`ğŸ“Š Average posts per call: ${avgPosts.toFixed(1)}`)
    console.log(`â±ï¸ Average duration: ${avgDuration.toFixed(2)}s`)
    
    // Success criteria
    const minExpectedPosts = 1 // At least 1 post should be fetched in most calls
    const successfulWithPosts = successfulCalls.filter(r => r.posts >= minExpectedPosts).length
    
    console.log(`\nğŸ¯ SUCCESS CRITERIA:`)
    console.log(`- Calls that fetched â‰¥${minExpectedPosts} posts: ${successfulWithPosts}/3`)
    console.log(`- All calls successful: ${successfulCalls.length === 3 ? 'âœ…' : 'âŒ'}`)
    console.log(`- Average response time < 30s: ${avgDuration < 30 ? 'âœ…' : 'âŒ'}`)
    
    if (successfulWithPosts >= 2 && successfulCalls.length >= 2 && avgDuration < 30) {
      console.log('\nğŸ‰ ENHANCED FETCHING ALGORITHM: PASSED')
      console.log('âœ… The algorithm successfully ensures consistent content fetching!')
    } else {
      console.log('\nâš ï¸ ENHANCED FETCHING ALGORITHM: NEEDS IMPROVEMENT')
      console.log('âŒ The algorithm may need further optimization.')
    }
    
    // Show sample of recent content
    console.log('\nğŸ“„ Recent Content Sample:')
    const recentContent = await Content.find({ source: redditSource.name })
      .sort({ createdAt: -1 })
      .limit(3)
      .select('title source createdAt metadata.fetchStrategy')
    
    recentContent.forEach((content, index) => {
      const age = Math.floor((Date.now() - new Date(content.createdAt)) / (1000 * 60))
      console.log(`${index + 1}. ${content.title}`)
      console.log(`   Source: ${content.source} | Age: ${age}m | Strategy: ${content.metadata?.fetchStrategy || 'N/A'}`)
    })
    
  } catch (error) {
    console.error('âŒ Test failed:', error.message)
    console.error('Stack trace:', error.stack)
  }
}

// Helper function to check if the server is running
async function checkServerHealth() {
  try {
    const response = await fetch('http://localhost:3000/api/health', {
      signal: AbortSignal.timeout(5000)
    })
    return response.ok
  } catch (error) {
    return false
  }
}

// Run the test
if (import.meta.url === `file://${process.argv[1]}`) {
  console.log('ğŸ¥ Checking server health...')
  
  const isServerRunning = await checkServerHealth()
  
  if (!isServerRunning) {
    console.log('âŒ Server is not running at http://localhost:3000')
    console.log('ğŸ’¡ Please start the development server first:')
    console.log('   npm run dev')
    process.exit(1)
  }
  
  testEnhancedFetching()
    .then(() => {
      console.log('\nâœ… Test completed')
      process.exit(0)
    })
    .catch((error) => {
      console.error('âŒ Test failed:', error)
      process.exit(1)
    })
}

export default testEnhancedFetching
